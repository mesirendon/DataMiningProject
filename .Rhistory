ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_line(
aes(x = dataset$Level, y = predict(lineal_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Linear Regression)') +
xlab('Level') +
ylab('Salary')
polynomial_regressor <- lm(
formula = Salary ~ .,
data = dataset
)
ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_line(
aes(x = dataset$Level, y = predict(polynomial_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Polynomial Regression)') +
xlab('Level') +
ylab('Salary')
# Fitting Polynomial Regression to the dataset
dataset$Level2 <- dataset$Level ^ 2
View(dataset)
ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_line(
aes(x = dataset$Level, y = predict(polynomial_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Polynomial Regression)') +
xlab('Level') +
ylab('Salary')
polynomial_regressor <- lm(
formula = Salary ~ .,
data = dataset
)
ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_line(
aes(x = dataset$Level, y = predict(polynomial_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Polynomial Regression)') +
xlab('Level') +
ylab('Salary')
summary(polynomial_regressor)
dataset$Level3 <- dataset$Level ^ 3
polynomial_regressor <- lm(
formula = Salary ~ .,
data = dataset
)
summary(polynomial_regressor)
ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_line(
aes(x = dataset$Level, y = predict(polynomial_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Polynomial Regression)') +
xlab('Level') +
ylab('Salary')
dataset$Level4 <- dataset$Level ^ 4
polynomial_regressor <- lm(
formula = Salary ~ .,
data = dataset
)
summary(polynomial_regressor)
ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_line(
aes(x = dataset$Level, y = predict(polynomial_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Polynomial Regression)') +
xlab('Level') +
ylab('Salary')
# Predicting a new result with the Linear Regression
y_pred = predict(lineal_regressor, newdata = data.frame(Level = 6.5))
# Predicting a new result with the Linear Regression
y_pred = predict(lineal_regressor, newdata = data.frame(Level = 6.5))
y_pred
# Predicting a new result with the Polynomial Regression
real_data <- data.frame(Level = 6.5, Level2 = 6.5^2, Level3 = 6.5^3, Level4 = 6.5^4)
real_data
y_pred = predict(polynomial_regressor, newdata = real_data)
y_pred
ggplot() +
geom_point(
aes(x = dataset$Level, y = dataset$Salary),
col = 'red'
) +
geom_point(
aes(x = real_data$Level, y = y_pred),
col = 'green'
) +
geom_line(
aes(x = dataset$Level, y = predict(polynomial_regressor, newdata = dataset)),
col = 'blue'
) +
ggtitle('Truth or Bluff (Polynomial Regression)') +
xlab('Level') +
ylab('Salary')
summary(polynomial_regressor)
# Regression Template
rm(list = ls())
gc()
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
View(dataset)
dataset = dataset[2:3]
View(dataset)
# Fitting the SVR to the dataset
# install.packages('e1071')
library(e1071)
regressor <- svm(
formula = Salary ~ .,
data = dataset,
type = 'eps-regression'
)
summary(regressor)
# Predicting a new result
data.to.predict <- data.frame(Level = 6.5)
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
# Visualising the SVR results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (SVR)') +
xlab('Level') +
ylab('Salary')
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.1)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Regression Model)') +
xlab('Level') +
ylab('Salary')
# Regression Template
rm(list = ls())
gc()
setwd("~/Documents/Data Science/Machine Learning A-Z/Part 2 - Regression/Section 8 - Decision Tree Regression")
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
View(dataset)
# Fitting the Decision Tree Regression to the dataset
# install.packages('rpart')
library(rpart)
regressor <- rpart(
formula = Salary ~ .,
data = dataset,
control = rpart.control(minsplit = 1)
)
summary(regressor)
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
# Visualising the Regression Model results
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = dataset$Level, y = predict(regressor, newdata = dataset)),
colour = 'blue') +
ggtitle('Truth or Bluff (Decision Tree Regression)') +
xlab('Level') +
ylab('Salary')
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Regression Model)') +
xlab('Level') +
ylab('Salary')
# Regression Template
rm(list = ls())
gc()
# Importing the dataset
dataset = read.csv('Position_Salaries.csv')
dataset = dataset[2:3]
View(dataset)
# Fitting the Random Forest Regression to the dataset
# install.packages('randomForest')
library(randomForest)
set.seed(1234)
str(datas)
str(dataset)
dataset
dataset[1]
str(dataset[1])
dataset[2]
str(dataset[2])
dataset$Salary
str(dataset$Salary)
regressor <- randomForest(
x = dataset[1],
y = dataset$Salary,
ntree = 10
)
summary(regressor)
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
y_pred
# Visualising the Random Forest Regression results (for higher resolution and smoother curve)
# install.packages('ggplot2')
library(ggplot2)
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.01)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.001)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(
x = dataset[1],
y = dataset$Salary,
ntree = 100
)
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.001)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
regressor <- randomForest(
x = dataset[1],
y = dataset$Salary,
ntree = 500
)
# Predicting a new result
y_pred = predict(regressor, data.frame(Level = 6.5))
x_grid = seq(min(dataset$Level), max(dataset$Level), 0.001)
ggplot() +
geom_point(aes(x = dataset$Level, y = dataset$Salary),
colour = 'red') +
geom_line(aes(x = x_grid, y = predict(regressor, newdata = data.frame(Level = x_grid))),
colour = 'blue') +
ggtitle('Truth or Bluff (Random Forest Regression)') +
xlab('Level') +
ylab('Salary')
summary(regressor)
setwd("~/Documents/Data Science/Machine Learning A-Z/Part 2 - Regression/Section 4 - Simple Linear Regression")
# Data Preprocessing Template
rm(list = ls())
gc()
# Importing the dataset
dataset <- read.csv('Salary_Data.csv')
# Splitting the dataset into the Training set and Test set
# install.packages('caTools')
library(caTools)
set.seed(123)
split <- sample.split(dataset$Salary, SplitRatio = 2/3)
training_set <- subset(dataset, split == TRUE)
test_set <- subset(dataset, split == FALSE)
# Fitting Simple Linear Regression to the Training Set
regressor <- lm(
formula = Salary ~ YearsExperience,
data = training_set
)
str(regressor)
summary(regressor)
y_pred <- predict(regressor, newdata = test_set)
# Visualizing the training set
# install.packages('ggplot2')
library(ggplot2)
ggplot() +
geom_point(
aes(x = test_set$YearsExperience, y = test_set$Salary),
col = 'green'
) +
geom_point(
aes(x = training_set$YearsExperience, y = training_set$Salary),
col = 'red'
) +
geom_line(
aes(x = training_set$YearsExperience, y = predict(regressor, newdata = training_set)),
col = 'blue'
) +
ggtitle('Salary Vs Experience (Training Set)') +
xlab('Years of experience') +
ylab('Salary')
setwd("~/Projects/University/MSc/1/DataMining/Project")
# Dataset loading
rm(list = ls())
gc()
births <- read.table("births.csv", header = TRUE, sep = ",")
str(births)
summary(births)
summary(births$MEDUC)
summary(births$PAY)
library(lattice)
###################################################################################################
### Frequency
###################################################################################################
births.dow <- table(births$DOB_WK)
births.dow
barchart(
births.dow,
xlab="Day of Week",
ylab = "Number of births",
col="red",
main = "Frequency of births by day of the week",
horizontal = FALSE,
panel = function(...) {
args <- list(...)
panel.text(args$x, args$y, args$y, pos=3, offset=1)
panel.barchart(...)
}
)
births.dmm <- table(births$DOB_MM)
births.dmm
barchart(
births.dmm,
xlab="Month of the year",
ylab = "Number of births",
col="blue",
main = "Frequency of births by month",
horizontal = FALSE,
panel = function(...) {
args <- list(...)
panel.text(args$x, args$y, args$y, pos=3, offset=1)
panel.barchart(...)
}
)
births.dmeth <- table(births$DMETH_REC)
births.dmeth
barchart(
births.dmeth,
xlab="Birth method",
ylab = "Number of births",
col="blue",
main = "Frequency of births by method",
horizontal = FALSE,
panel = function(...) {
args <- list(...)
panel.text(args$x, args$y, args$y, pos=3, offset=1)
panel.barchart(...)
}
)
births.bfacil <- table(births$BFACIL)
births.bfacil
barchart(
births.bfacil,
ylab="Birth place",
xlab = "Number of births",
col="blue",
main = "Frequency of births by place",
)
regressor <- lm(
formula = APGAR5 ~ .,
data = births
)
summary(regressor)
xxx <- function() {
for (i in 10){
string <- paste("text = ", i)
file <- paste(string,".txt")
write(string, file = file)
}
}
xxx()
xxx <- function() {
for (i in 10){
string <- paste("text = ", i)
file <- paste(i,".txt")
write(string, file = file)
}
}
xxx()
xxx <- function() {
for (i in 1:10){
string <- paste("text = ", i)
file <- paste(i,".txt")
write(string, file = file)
}
}
xxx()
backwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = Profit ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
print(numVars)
numVars = numVars - 1
file <- paste(i, ".txt")
write(summary(regressor), file = file)
}
return(summary(regressor))
}
backwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = APGAR5 ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
print(numVars)
numVars = numVars - 1
file <- paste(i, ".txt")
write(summary(regressor), file = file)
}
return(summary(regressor))
}
SL = 0.05
backwardElimination(births, SL)
# Dataset loading
rm(list = ls())
gc()
# Dataset loading
rm(list = ls())
gc()
births <- read.table("births.csv", header = TRUE, sep = ",")
backwardElimination <- function(x, sl) {
numVars = length(x)
for (i in c(1:numVars)){
regressor = lm(formula = APGAR5 ~ ., data = x)
maxVar = max(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"])
if (maxVar > sl){
j = which(coef(summary(regressor))[c(2:numVars), "Pr(>|t|)"] == maxVar)
x = x[, -j]
}
print(numVars)
numVars = numVars - 1
file <- paste(i, ".txt")
sink(file = file)
print(summary(regressor))
sink()
}
return(summary(regressor))
}
SL = 0.05
backwardElimination(births, SL)
births$APGAR5
split = sample.split(births$APGAR5, SplitRatio = 0.8)
training_set = subset(births, split == TRUE)
test_set = subset(births, split == FALSE)
test_set
ggplot() +
geom_point(aes(x = training_set$DBWT, y = training_set$APGAR5),
colour = 'red') +
geom_line(aes(x = training_set$DBWT, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('APGAR5 vs DBWT (Training set)') +
xlab('Weight') +
ylab('APGAR Score')
regressor <- lm(
formula = APGAR5 ~ DBWT,
data = training_set
)
library(ggplot2)
ggplot() +
geom_point(aes(x = training_set$DBWT, y = training_set$APGAR5),
colour = 'red') +
geom_line(aes(x = training_set$DBWT, y = predict(regressor, newdata = training_set)),
colour = 'blue') +
ggtitle('APGAR5 vs DBWT (Training set)') +
xlab('Weight') +
ylab('APGAR Score')
rm(list = ls())
gc()
